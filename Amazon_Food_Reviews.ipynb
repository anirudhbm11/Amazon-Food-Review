{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"F:\\Amazon reviews\\Reviews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Id', 'ProductId', 'UserId', 'ProfileName', 'HelpfulnessNumerator',\n",
       "       'HelpfulnessDenominator', 'Score', 'Time', 'Summary', 'Text'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   ProductId          UserId                      ProfileName  \\\n",
       "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
       "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                     1                       1      5  1303862400   \n",
       "1                     0                       0      1  1346976000   \n",
       "2                     1                       1      4  1219017600   \n",
       "3                     3                       3      2  1307923200   \n",
       "4                     0                       0      5  1350777600   \n",
       "\n",
       "                 Summary                                               Text  \n",
       "0  Good Quality Dog Food  I have bought several of the Vitality canned d...  \n",
       "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n",
       "2  \"Delight\" says it all  This is a confection that has been around a fe...  \n",
       "3         Cough Medicine  If you are looking for the secret ingredient i...  \n",
       "4            Great taffy  Great taffy at a great price.  There was a wid...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment(x):\n",
    "    if x<3:\n",
    "        return \"positive\"\n",
    "    else:\n",
    "        return \"negative\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(568454, 10)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(525814, 10)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_removed = df[df['Score']!=3]\n",
    "df = df_removed\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Score\"] = df[\"Score\"].map(sentiment)\n",
    "#df[\"Score\"] = df[\"Score\"].apply(lambda x:\"positive\" if x>3 else \"negative\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(364171, 10)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop_duplicates(subset = {\"UserId\",\"ProfileName\",\"Time\",\"Text\"})\n",
    "final_df = df[df['HelpfulnessNumerator']<=df[\"HelpfulnessDenominator\"]] \n",
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000,)\n"
     ]
    }
   ],
   "source": [
    "X = final_df[\"Text\"].head(100000)\n",
    "print(X.shape)\n",
    "y = final_df[\"Score\"].head(100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords           \n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = set(stopwords.words('english')) \n",
    "import re\n",
    "temp =[]\n",
    "snow = nltk.stem.SnowballStemmer('english')\n",
    "for sentence in X:\n",
    "    sentence = sentence.lower()                \n",
    "    cleanr = re.compile('<.*?>')\n",
    "    sentence = re.sub(cleanr, ' ', sentence)    \n",
    "    sentence = re.sub(r'[?|!|\\'|\"|#]',r'',sentence)\n",
    "    sentence = re.sub(r'[.|,|)|(|\\|/]',r' ',sentence) \n",
    "    \n",
    "    words = [snow.stem(word) for word in sentence.split() if word not in stopwords.words('english')]\n",
    "    temp.append(words)\n",
    "    \n",
    "X = temp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['bought', 'sever', 'vital', 'can', 'dog', 'food', 'product', 'found', 'good', 'qualiti', 'product', 'look', 'like', 'stew', 'process', 'meat', 'smell', 'better', 'labrador', 'finicki', 'appreci', 'product', 'better'], ['product', 'arriv', 'label', 'jumbo', 'salt', 'peanut', 'peanut', 'actual', 'small', 'size', 'unsalt', 'sure', 'error', 'vendor', 'intend', 'repres', 'product', 'jumbo']]\n"
     ]
    }
   ],
   "source": [
    "print(X[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' bought sever vital can dog food product found good qualiti product look like stew process meat smell better labrador finicki appreci product better', ' product arriv label jumbo salt peanut peanut actual small size unsalt sure error vendor intend repres product jumbo']\n"
     ]
    }
   ],
   "source": [
    "sent = []\n",
    "for row in X:\n",
    "    sequ = ''\n",
    "    for word in row:\n",
    "        sequ = sequ + ' ' + word\n",
    "    sent.append(sequ)\n",
    "\n",
    "X = sent\n",
    "print(X[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array(['negative', 'positive'], dtype=object), array([83899, 16101], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(y,return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 3115849)\t0.07011653073586861\n",
      "  (0, 247991)\t0.06078651148202399\n",
      "  (0, 2190151)\t0.07212772466086945\n",
      "  (0, 2135427)\t0.2471687820637165\n",
      "  (0, 3403623)\t0.06248803428841047\n",
      "  (0, 2930915)\t0.13402913140610523\n",
      "  (0, 76755)\t0.05688031392899929\n",
      "  (0, 3605806)\t0.05574242335508055\n",
      "  (0, 3586057)\t0.05752105130870878\n",
      "  (0, 4227877)\t0.11136715097859334\n",
      "  (0, 3854865)\t0.05591161012269494\n",
      "  (0, 1311743)\t0.10703676258534266\n",
      "  (0, 4295751)\t0.09009125413696044\n",
      "  (0, 2076971)\t0.0932105464357536\n",
      "  (0, 3314597)\t0.10977111311434166\n",
      "  (0, 3117499)\t0.09498619033075846\n",
      "  (0, 249478)\t0.15355684131869216\n",
      "  (0, 2191381)\t0.16646120616482413\n",
      "  (0, 2135469)\t0.16646120616482413\n",
      "  (0, 3406972)\t0.13551711101192365\n",
      "  (0, 2932892)\t0.13632208807930948\n",
      "  (0, 2930946)\t0.15355684131869216\n",
      "  (0, 81222)\t0.1424527876708418\n",
      "  (0, 3611035)\t0.10372945448087148\n",
      "  (0, 3591766)\t0.16646120616482413\n",
      "  (0, 4228016)\t0.16646120616482413\n",
      "  (0, 3856469)\t0.16646120616482413\n",
      "  (0, 1311965)\t0.16646120616482413\n",
      "  (0, 4296033)\t0.16646120616482413\n",
      "  (0, 2077327)\t0.16646120616482413\n",
      "  (0, 3314746)\t0.15669943100016853\n",
      "  (0, 3127834)\t0.1607509337530295\n",
      "  (0, 3117549)\t0.16646120616482413\n",
      "  (0, 249480)\t0.16646120616482413\n",
      "  (0, 2191382)\t0.16646120616482413\n",
      "  (0, 2135470)\t0.16646120616482413\n",
      "  (0, 3406984)\t0.1607509337530295\n",
      "  (0, 2932893)\t0.16646120616482413\n",
      "  (0, 2930950)\t0.16646120616482413\n",
      "  (0, 81232)\t0.16646120616482413\n",
      "  (0, 3611159)\t0.16646120616482413\n",
      "  (0, 3591767)\t0.16646120616482413\n",
      "  (0, 4228017)\t0.16646120616482413\n",
      "  (0, 3856470)\t0.16646120616482413\n",
      "  (0, 1311966)\t0.16646120616482413\n",
      "  (0, 4296034)\t0.16646120616482413\n",
      "  (0, 2077328)\t0.16646120616482413\n",
      "  (0, 3314747)\t0.16646120616482413\n"
     ]
    }
   ],
   "source": [
    "final_tf = X\n",
    "tf_idf = TfidfVectorizer(ngram_range = (1,3))\n",
    "tf_data = tf_idf.fit_transform(final_tf)\n",
    "print(tf_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 4538920)\n"
     ]
    }
   ],
   "source": [
    "print(tf_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\IITS\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(tf_data,y,test_size=0.3,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lg=LogisticRegression()\n",
    "lg.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8433333333333334 0.8427714285714286\n"
     ]
    }
   ],
   "source": [
    "pred=lg.predict(x_test)\n",
    "score=lg.score(x_test,y_test)\n",
    "score2=lg.score(x_train,y_train)\n",
    "print(score,score2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "RFC = RandomForestClassifier()\n",
    "RFC.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8422 0.9643142857142857\n"
     ]
    }
   ],
   "source": [
    "pred=RFC.predict(x_test)\n",
    "score=RFC.score(x_test,y_test)\n",
    "score2=RFC.score(x_train,y_train)\n",
    "print(score,score2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf=MultinomialNB()\n",
    "clf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8427714285714286 0.8433333333333334\n"
     ]
    }
   ],
   "source": [
    "score = clf.score(x_train,y_train)\n",
    "score2 = clf.score(x_test,y_test)\n",
    "print(score,score2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
